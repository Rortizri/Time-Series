
MACHINE LEARNING FUNDAMENTALS


- In this part you will find code related to the fundamentals of Machine Learning. It will be constantly updated with modules to cover the main ML topics


Linear Regression using Gradient Descent.

- Linear Regression fits a linear model with coefficients, to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation.
Gradient Descent is an iterative optimization algorithm to find the minimum of a function. Here that function is our Loss Function.


Quantile regression models 

- Shows the relationship between a set of predictor (independent) variables and specific percentiles (or "quantiles") of a target (dependent) variable, most often the median. It has two main advantages over Ordinary Least Squares regression:
Quantile regression makes no assumptions about the distribution of the target variable.
Quantile regression tends to resist the influence of outlying observations.


- ğŸ‘€ Iâ€™m interested in Machine Learning, and Deep Learning for Economics.
- ğŸŒ± Iâ€™m currently learning Data Science.
- ğŸ’ï¸ Iâ€™m looking to collaborate on ...
- ğŸ“« How to reach me ...

<!---
Rortizri/Rortizri is a âœ¨ special âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.
You can click the Preview link to take a look at your changes.
--->
